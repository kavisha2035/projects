{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99b1ed33-9d54-45c8-abd3-891e9799e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.signal import welch\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# === Constants ===\n",
    "sampling_rate = 250\n",
    "segment_duration = 3  # in seconds\n",
    "segment_length = sampling_rate * segment_duration\n",
    "data_dir = \"C:/Users/kavis/helloji/1/\"  # EEG Session 1 folder\n",
    "label_map = [1, 2, 3, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 1, 2, 3, 2, 2, 3, 3, 0, 3, 0, 3]  # Session 1 labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3772fb91-2474-42df-a993-eed0a1e04401",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all, segment_meta = [], [], []\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".mat\"):\n",
    "        mat = scipy.io.loadmat(os.path.join(data_dir, filename))\n",
    "        subject_id = int(filename.split('_')[0])\n",
    "        prefix = [k.split('_')[0] for k in mat.keys() if '_eeg1' in k][0]\n",
    "\n",
    "        for trial in range(1, 25):\n",
    "            key = f\"{prefix}_eeg{trial}\"\n",
    "            if key in mat:\n",
    "                eeg = mat[key]\n",
    "                label = label_map[trial - 1]\n",
    "                for seg_idx in range(eeg.shape[1] // segment_length):\n",
    "                    segment = eeg[:, seg_idx * segment_length:(seg_idx + 1) * segment_length]\n",
    "                    if segment.shape[1] == segment_length:\n",
    "                        X_all.append(segment)\n",
    "                        y_all.append(label)\n",
    "                        segment_meta.append([subject_id, trial])\n",
    "\n",
    "X_all = np.array(X_all, dtype=np.float32)\n",
    "y_all = np.array(y_all)\n",
    "segment_meta = np.array(segment_meta)\n",
    "y_cat = to_categorical(y_all, num_classes=4)\n",
    "\n",
    "np.save(\"segment_meta.npy\", segment_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fb5e5d6-3038-4d3e-9f20-72d4e09cbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_de_features(segment):\n",
    "    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 14), 'beta': (14, 31), 'gamma': (31, 50)}\n",
    "    features = []\n",
    "    for ch in segment:\n",
    "        freqs, psd = welch(ch, fs=250, nperseg=256)\n",
    "        band_de = []\n",
    "        for band in bands.values():\n",
    "            idx = (freqs >= band[0]) & (freqs <= band[1])\n",
    "            power = np.trapz(psd[idx], freqs[idx])\n",
    "            de = 0.5 * np.log2(2 * np.pi * np.e * power) if power > 0 else 0\n",
    "            band_de.append(de)\n",
    "        features.append(band_de)\n",
    "    return np.array(features)\n",
    "\n",
    "def compute_psd_features(X):\n",
    "    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 13), 'beta': (13, 30), 'gamma': (30, 50)}\n",
    "    psd_feats = np.zeros((X.shape[0], 62, len(bands)))\n",
    "    for i in range(X.shape[0]):\n",
    "        for ch in range(62):\n",
    "            freqs, psd = welch(X[i, ch], fs=250, nperseg=256)\n",
    "            for j, (low, high) in enumerate(bands.values()):\n",
    "                idx = (freqs >= low) & (freqs <= high)\n",
    "                psd_feats[i, ch, j] = np.trapz(psd[idx], freqs[idx])\n",
    "    return psd_feats\n",
    "\n",
    "\n",
    "\n",
    "# Load precomputed DE and PSD feature files\n",
    "X_de = np.load(\"X_de4.npy\")     # Shape: (samples, 62, 5)\n",
    "X_psd = np.load(\"X_psd4.npy\")   # Shape: (samples, 62, 5)\n",
    "\n",
    "# Concatenate along the last axis → shape: (samples, 62, 10)\n",
    "X_feat_all = np.concatenate([X_de, X_psd], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0967eeec-f4ae-4106-91da-6c06bbce22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eye_trial = np.load(\"X_eye_session1.npy\")  # shape (120, 19)\n",
    "segment_meta = np.load(\"segment_meta.npy\")\n",
    "\n",
    "X_eye_segment = np.zeros((segment_meta.shape[0], X_eye_trial.shape[1]))\n",
    "for i, (subj, trial) in enumerate(segment_meta):\n",
    "    trial_index = (subj - 1) * 24 + (trial - 1)\n",
    "    X_eye_segment[i] = X_eye_trial[trial_index]\n",
    "\n",
    "np.save(\"X_eye_4520.npy\", X_eye_segment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a659c90a-1a1e-4221-afeb-c4ce0d4f276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    res = Add()([x, inputs])\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    return Add()([x, res])\n",
    "\n",
    "def channel_attention_block(x):\n",
    "    attn = Dense(1, activation='tanh')(x)\n",
    "    attn = Softmax(axis=1)(attn)\n",
    "    return Multiply()([x, attn])\n",
    "\n",
    "def build_triple_branch_model(input_shape_eeg=(62, 750),\n",
    "                               input_shape_feat=(62, 10),\n",
    "                               input_shape_eye=(19,),\n",
    "                               num_classes=4):\n",
    "    # Branch 1: Raw EEG\n",
    "    eeg_input = Input(shape=input_shape_eeg, name=\"eeg_input\")\n",
    "    x1 = Permute((2, 1))(eeg_input)\n",
    "    x1 = SeparableConv1D(64, 5, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = SeparableConv1D(128, 3, padding='same', activation='relu')(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = MaxPooling1D(pool_size=2)(x1)\n",
    "    x1 = Bidirectional(GRU(64, return_sequences=True))(x1)\n",
    "    x1 = transformer_encoder(x1, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "    attn = Dense(1, activation='tanh')(x1)\n",
    "    attn = Softmax(axis=1)(attn)\n",
    "    x1 = Multiply()([x1, attn])\n",
    "    x1 = GlobalAveragePooling1D()(x1)\n",
    "    x1 = Dropout(0.3)(x1)\n",
    "\n",
    "    # Branch 2: EEG Features\n",
    "    feat_input = Input(shape=input_shape_feat, name=\"eeg_feat_input\")\n",
    "    x2 = Dense(64, activation='relu')(feat_input)\n",
    "    x2 = channel_attention_block(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    x2 = Dropout(0.3)(x2)\n",
    "\n",
    "    # Branch 3: Eye Features\n",
    "    eye_input = Input(shape=input_shape_eye, name=\"eye_input\")\n",
    "    x3 = Dense(32, activation='relu')(eye_input)\n",
    "    x3 = Dense(32, activation='relu')(x3)\n",
    "    x3 = Dropout(0.3)(x3)\n",
    "\n",
    "    # Fusion\n",
    "    x = Concatenate()([x1, x2, x3])\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[eeg_input, feat_input, eye_input], outputs=output)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0748a3aa-5aea-4bb9-a3f9-8e1eb434c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class EEGTripleInputGenerator(Sequence):\n",
    "    def __init__(self, X1, X2, X3, y, indices, batch_size=32, shuffle=True):\n",
    "        self.X1, self.X2, self.X3, self.y = X1, X2, X3, y\n",
    "        self.indices = np.array(indices)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        batch_idx = self.indices[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        return {\n",
    "            \"eeg_input\": self.X1[batch_idx],\n",
    "            \"eeg_feat_input\": self.X2[batch_idx],\n",
    "            \"eye_input\": self.X3[batch_idx],\n",
    "        }, self.y[batch_idx]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def run_kfold_training(X_eeg, X_feat, X_eye, y_cat, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(y_cat)))):\n",
    "        print(f\"\\n Fold {fold + 1}/{n_splits}\")\n",
    "        train_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, train_idx)\n",
    "        val_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, val_idx, shuffle=False)\n",
    "\n",
    "        model = build_triple_branch_model()\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "        lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "        model.fit(train_gen, validation_data=val_gen, epochs=30, callbacks=[es, lr], verbose=1)\n",
    "\n",
    "        val_acc = model.evaluate(val_gen, verbose=0)[1]\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\" Fold {fold + 1} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n Average Validation Accuracy over {n_splits} folds: {np.mean(val_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b66a4b-f7dd-450f-aaff-d64c9dccc03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fold 1/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 807ms/step - accuracy: 0.3219 - loss: 6.2680 - val_accuracy: 0.4521 - val_loss: 1.8381 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 813ms/step - accuracy: 0.3880 - loss: 3.0519 - val_accuracy: 0.4830 - val_loss: 1.3030 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 790ms/step - accuracy: 0.4328 - loss: 1.4790 - val_accuracy: 0.5667 - val_loss: 1.1620 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 758ms/step - accuracy: 0.4886 - loss: 1.4804 - val_accuracy: 0.6390 - val_loss: 1.1552 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 266ms/step - accuracy: 0.5308 - loss: 1.2866 - val_accuracy: 0.6822 - val_loss: 1.0054 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.5802 - loss: 1.1587 - val_accuracy: 0.7220 - val_loss: 0.9517 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 295ms/step - accuracy: 0.6157 - loss: 1.1260 - val_accuracy: 0.7647 - val_loss: 0.9034 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 318ms/step - accuracy: 0.6361 - loss: 1.0738 - val_accuracy: 0.7677 - val_loss: 0.8525 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 306ms/step - accuracy: 0.6619 - loss: 0.9980 - val_accuracy: 0.7817 - val_loss: 0.8303 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 306ms/step - accuracy: 0.6834 - loss: 0.9642 - val_accuracy: 0.7754 - val_loss: 0.8251 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 284ms/step - accuracy: 0.6888 - loss: 1.0970 - val_accuracy: 0.8134 - val_loss: 0.7817 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 268ms/step - accuracy: 0.7172 - loss: 0.9006 - val_accuracy: 0.8389 - val_loss: 0.7175 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 330ms/step - accuracy: 0.7491 - loss: 0.8542 - val_accuracy: 0.8477 - val_loss: 0.7070 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 293ms/step - accuracy: 0.7683 - loss: 0.8393 - val_accuracy: 0.8813 - val_loss: 0.6718 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 309ms/step - accuracy: 0.7778 - loss: 0.8177 - val_accuracy: 0.8813 - val_loss: 0.6435 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 293ms/step - accuracy: 0.8011 - loss: 0.7662 - val_accuracy: 0.9012 - val_loss: 0.6171 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 276ms/step - accuracy: 0.8064 - loss: 0.7804 - val_accuracy: 0.8805 - val_loss: 0.6468 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 266ms/step - accuracy: 0.8128 - loss: 0.7584 - val_accuracy: 0.9074 - val_loss: 0.6008 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 268ms/step - accuracy: 0.8351 - loss: 0.7349 - val_accuracy: 0.9045 - val_loss: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 267ms/step - accuracy: 0.8380 - loss: 0.7319 - val_accuracy: 0.9215 - val_loss: 0.5664 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 274ms/step - accuracy: 0.8449 - loss: 0.7125 - val_accuracy: 0.9170 - val_loss: 0.5674 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 265ms/step - accuracy: 0.8482 - loss: 0.6829 - val_accuracy: 0.9255 - val_loss: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 263ms/step - accuracy: 0.8611 - loss: 0.6653 - val_accuracy: 0.9266 - val_loss: 0.5399 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 266ms/step - accuracy: 0.8523 - loss: 0.6732 - val_accuracy: 0.9366 - val_loss: 0.5391 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.8669 - loss: 0.6501 - val_accuracy: 0.9347 - val_loss: 0.5267 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 260ms/step - accuracy: 0.8775 - loss: 0.6389 - val_accuracy: 0.9336 - val_loss: 0.5315 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 263ms/step - accuracy: 0.8812 - loss: 0.6339 - val_accuracy: 0.9421 - val_loss: 0.5203 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 264ms/step - accuracy: 0.8776 - loss: 0.6298 - val_accuracy: 0.9381 - val_loss: 0.5149 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 260ms/step - accuracy: 0.8785 - loss: 0.6337 - val_accuracy: 0.9296 - val_loss: 0.5248 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 233ms/step - accuracy: 0.8825 - loss: 0.6278 - val_accuracy: 0.9469 - val_loss: 0.5004 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      " Fold 1 Accuracy: 0.9469\n",
      "\n",
      " Fold 2/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 795ms/step - accuracy: 0.3010 - loss: 9.7663 - val_accuracy: 0.3820 - val_loss: 1.9112 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 418ms/step - accuracy: 0.3668 - loss: 2.0364 - val_accuracy: 0.4229 - val_loss: 1.4615 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 239ms/step - accuracy: 0.3962 - loss: 1.4093 - val_accuracy: 0.4174 - val_loss: 4.2051 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 239ms/step - accuracy: 0.4159 - loss: 1.3375 - val_accuracy: 0.4956 - val_loss: 1.2162 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 275ms/step - accuracy: 0.4406 - loss: 1.3552 - val_accuracy: 0.5000 - val_loss: 1.2037 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 281ms/step - accuracy: 0.4439 - loss: 1.2810 - val_accuracy: 0.5015 - val_loss: 1.1867 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 265ms/step - accuracy: 0.4500 - loss: 1.2962 - val_accuracy: 0.5000 - val_loss: 1.1855 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 255ms/step - accuracy: 0.4618 - loss: 1.2448 - val_accuracy: 0.4428 - val_loss: 1.4137 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.4688 - loss: 1.3849 - val_accuracy: 0.5247 - val_loss: 1.1335 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 294ms/step - accuracy: 0.4936 - loss: 1.3006 - val_accuracy: 0.4395 - val_loss: 1.8434 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 311ms/step - accuracy: 0.4916 - loss: 1.2161 - val_accuracy: 0.5225 - val_loss: 1.1395 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 304ms/step - accuracy: 0.5098 - loss: 1.1762 - val_accuracy: 0.5317 - val_loss: 1.1248 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 287ms/step - accuracy: 0.5120 - loss: 1.2052 - val_accuracy: 0.5136 - val_loss: 1.1384 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 257ms/step - accuracy: 0.5143 - loss: 1.2018 - val_accuracy: 0.5789 - val_loss: 1.0692 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 258ms/step - accuracy: 0.5209 - loss: 1.1847 - val_accuracy: 0.5878 - val_loss: 1.0654 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 275ms/step - accuracy: 0.5317 - loss: 1.1440 - val_accuracy: 0.5937 - val_loss: 1.0372 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 266ms/step - accuracy: 0.5538 - loss: 1.1272 - val_accuracy: 0.6044 - val_loss: 1.0394 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 243ms/step - accuracy: 0.5597 - loss: 1.1039 - val_accuracy: 0.6213 - val_loss: 1.0064 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 235ms/step - accuracy: 0.5834 - loss: 1.0860 - val_accuracy: 0.6298 - val_loss: 0.9836 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 237ms/step - accuracy: 0.5774 - loss: 1.0831 - val_accuracy: 0.6449 - val_loss: 0.9542 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 250ms/step - accuracy: 0.6121 - loss: 1.0449 - val_accuracy: 0.6822 - val_loss: 0.9379 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 303ms/step - accuracy: 0.6392 - loss: 0.9945 - val_accuracy: 0.7404 - val_loss: 0.8498 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 236ms/step - accuracy: 0.6740 - loss: 0.9479 - val_accuracy: 0.7869 - val_loss: 0.7901 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 253ms/step - accuracy: 0.7059 - loss: 0.9374 - val_accuracy: 0.8149 - val_loss: 0.7611 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 262ms/step - accuracy: 0.7188 - loss: 0.8804 - val_accuracy: 0.8256 - val_loss: 0.7419 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 257ms/step - accuracy: 0.7528 - loss: 0.8376 - val_accuracy: 0.8577 - val_loss: 0.6995 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.7591 - loss: 0.8172 - val_accuracy: 0.8864 - val_loss: 0.6277 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 236ms/step - accuracy: 0.7864 - loss: 0.7971 - val_accuracy: 0.8890 - val_loss: 0.6334 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 259ms/step - accuracy: 0.7930 - loss: 0.7848 - val_accuracy: 0.8993 - val_loss: 0.6073 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 257ms/step - accuracy: 0.8019 - loss: 0.7534 - val_accuracy: 0.9100 - val_loss: 0.5868 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      " Fold 2 Accuracy: 0.9100\n",
      "\n",
      " Fold 3/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 260ms/step - accuracy: 0.3125 - loss: 10.9628 - val_accuracy: 0.4159 - val_loss: 1.9635 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 242ms/step - accuracy: 0.3605 - loss: 3.2264 - val_accuracy: 0.4314 - val_loss: 1.4518 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 252ms/step - accuracy: 0.3903 - loss: 1.8020 - val_accuracy: 0.4558 - val_loss: 1.2775 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 233ms/step - accuracy: 0.4065 - loss: 1.4430 - val_accuracy: 0.4834 - val_loss: 1.2285 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 246ms/step - accuracy: 0.4278 - loss: 1.3125 - val_accuracy: 0.4996 - val_loss: 1.1698 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 238ms/step - accuracy: 0.4433 - loss: 1.2523 - val_accuracy: 0.5011 - val_loss: 1.1372 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 305ms/step - accuracy: 0.4726 - loss: 1.2149 - val_accuracy: 0.5188 - val_loss: 1.1354 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 302ms/step - accuracy: 0.4712 - loss: 1.2032 - val_accuracy: 0.5332 - val_loss: 1.1005 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 296ms/step - accuracy: 0.4904 - loss: 1.1692 - val_accuracy: 0.5398 - val_loss: 1.0969 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 242ms/step - accuracy: 0.5159 - loss: 1.1425 - val_accuracy: 0.5937 - val_loss: 1.0467 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 226ms/step - accuracy: 0.5400 - loss: 1.1178 - val_accuracy: 0.5752 - val_loss: 1.0256 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 234ms/step - accuracy: 0.5580 - loss: 1.1036 - val_accuracy: 0.6361 - val_loss: 1.0011 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 226ms/step - accuracy: 0.5815 - loss: 1.0683 - val_accuracy: 0.6774 - val_loss: 0.9595 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 213ms/step - accuracy: 0.6046 - loss: 1.0404 - val_accuracy: 0.6652 - val_loss: 0.9484 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 227ms/step - accuracy: 0.6191 - loss: 1.0216 - val_accuracy: 0.6958 - val_loss: 0.9168 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 202ms/step - accuracy: 0.6424 - loss: 0.9924 - val_accuracy: 0.7718 - val_loss: 0.8719 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 204ms/step - accuracy: 0.6738 - loss: 0.9432 - val_accuracy: 0.8031 - val_loss: 0.8003 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 208ms/step - accuracy: 0.6925 - loss: 0.9195 - val_accuracy: 0.7906 - val_loss: 0.7948 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 202ms/step - accuracy: 0.7156 - loss: 0.8946 - val_accuracy: 0.8149 - val_loss: 0.7345 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 201ms/step - accuracy: 0.7292 - loss: 0.8645 - val_accuracy: 0.8285 - val_loss: 0.7180 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 204ms/step - accuracy: 0.7435 - loss: 0.8507 - val_accuracy: 0.8374 - val_loss: 0.7155 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 200ms/step - accuracy: 0.7573 - loss: 0.8201 - val_accuracy: 0.8709 - val_loss: 0.6712 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 200ms/step - accuracy: 0.7720 - loss: 0.7975 - val_accuracy: 0.8566 - val_loss: 0.6809 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 203ms/step - accuracy: 0.7839 - loss: 0.7918 - val_accuracy: 0.8875 - val_loss: 0.6503 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 200ms/step - accuracy: 0.8032 - loss: 0.7574 - val_accuracy: 0.8982 - val_loss: 0.6035 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 201ms/step - accuracy: 0.8193 - loss: 0.7273 - val_accuracy: 0.8956 - val_loss: 0.5980 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 196ms/step - accuracy: 0.8247 - loss: 0.7195 - val_accuracy: 0.9185 - val_loss: 0.5823 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 201ms/step - accuracy: 0.8359 - loss: 0.7086 - val_accuracy: 0.8971 - val_loss: 0.5864 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 227ms/step - accuracy: 0.8344 - loss: 0.6998 - val_accuracy: 0.9222 - val_loss: 0.5652 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 254ms/step - accuracy: 0.8470 - loss: 0.6872 - val_accuracy: 0.9167 - val_loss: 0.5675 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      " Fold 3 Accuracy: 0.9222\n",
      "\n",
      " Fold 4/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 251ms/step - accuracy: 0.3512 - loss: 5.6324 - val_accuracy: 0.5642 - val_loss: 2.5870 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2032s\u001b[0m 6s/step - accuracy: 0.5152 - loss: 2.3543 - val_accuracy: 0.7109 - val_loss: 1.0705 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 270ms/step - accuracy: 0.6152 - loss: 1.1495 - val_accuracy: 0.7611 - val_loss: 0.8769 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 246ms/step - accuracy: 0.6636 - loss: 0.9593 - val_accuracy: 0.8079 - val_loss: 0.7846 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 243ms/step - accuracy: 0.7114 - loss: 0.8944 - val_accuracy: 0.8190 - val_loss: 0.7607 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m970s\u001b[0m 3s/step - accuracy: 0.7377 - loss: 0.8549 - val_accuracy: 0.8024 - val_loss: 0.7662 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 250ms/step - accuracy: 0.7487 - loss: 0.8289 - val_accuracy: 0.8695 - val_loss: 0.6702 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 243ms/step - accuracy: 0.7760 - loss: 0.7958 - val_accuracy: 0.8857 - val_loss: 0.6469 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 239ms/step - accuracy: 0.7985 - loss: 0.7554 - val_accuracy: 0.8857 - val_loss: 0.6455 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 246ms/step - accuracy: 0.8017 - loss: 0.7524 - val_accuracy: 0.8986 - val_loss: 0.6257 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 250ms/step - accuracy: 0.8198 - loss: 0.7293 - val_accuracy: 0.8942 - val_loss: 0.6215 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 255ms/step - accuracy: 0.8268 - loss: 0.7138 - val_accuracy: 0.9067 - val_loss: 0.6016 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.8337 - loss: 0.6953 - val_accuracy: 0.9329 - val_loss: 0.5588 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 286ms/step - accuracy: 0.8435 - loss: 0.6755 - val_accuracy: 0.9174 - val_loss: 0.5712 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 258ms/step - accuracy: 0.8547 - loss: 0.6759 - val_accuracy: 0.9318 - val_loss: 0.5514 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 240ms/step - accuracy: 0.8635 - loss: 0.6562 - val_accuracy: 0.9111 - val_loss: 0.5697 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 262ms/step - accuracy: 0.8542 - loss: 0.6641 - val_accuracy: 0.9248 - val_loss: 0.5597 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 272ms/step - accuracy: 0.8738 - loss: 0.6346 - val_accuracy: 0.9458 - val_loss: 0.5313 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 249ms/step - accuracy: 0.8780 - loss: 0.6329 - val_accuracy: 0.9373 - val_loss: 0.5334 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 262ms/step - accuracy: 0.8815 - loss: 0.6362 - val_accuracy: 0.9307 - val_loss: 0.5308 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 270ms/step - accuracy: 0.8862 - loss: 0.6195 - val_accuracy: 0.9285 - val_loss: 0.5300 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 300ms/step - accuracy: 0.8822 - loss: 0.6236 - val_accuracy: 0.9089 - val_loss: 0.5825 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 270ms/step - accuracy: 0.8832 - loss: 0.6196 - val_accuracy: 0.9285 - val_loss: 0.5239 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 578ms/step - accuracy: 0.8921 - loss: 0.6122 - val_accuracy: 0.9248 - val_loss: 0.5414 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 814ms/step - accuracy: 0.8942 - loss: 0.6083 - val_accuracy: 0.8931 - val_loss: 0.5724 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767ms/step - accuracy: 0.8990 - loss: 0.5989\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 816ms/step - accuracy: 0.8990 - loss: 0.5989 - val_accuracy: 0.9141 - val_loss: 0.5554 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1158s\u001b[0m 3s/step - accuracy: 0.9120 - loss: 0.5729 - val_accuracy: 0.9310 - val_loss: 0.5228 - learning_rate: 5.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 831ms/step - accuracy: 0.9204 - loss: 0.5579 - val_accuracy: 0.9089 - val_loss: 0.5533 - learning_rate: 5.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 790ms/step - accuracy: 0.9270 - loss: 0.5593 - val_accuracy: 0.9322 - val_loss: 0.5221 - learning_rate: 5.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 827ms/step - accuracy: 0.9277 - loss: 0.5522 - val_accuracy: 0.9329 - val_loss: 0.5153 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      " Fold 4 Accuracy: 0.9329\n",
      "\n",
      " Fold 5/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 807ms/step - accuracy: 0.3453 - loss: 5.2254 - val_accuracy: 0.5579 - val_loss: 2.3401 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 807ms/step - accuracy: 0.5009 - loss: 1.8472 - val_accuracy: 0.6357 - val_loss: 1.0459 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 800ms/step - accuracy: 0.5587 - loss: 1.1130 - val_accuracy: 0.7024 - val_loss: 0.9478 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 929ms/step - accuracy: 0.6121 - loss: 1.0388 - val_accuracy: 0.7415 - val_loss: 0.8814 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 812ms/step - accuracy: 0.6577 - loss: 0.9721 - val_accuracy: 0.7751 - val_loss: 0.8222 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 861ms/step - accuracy: 0.6809 - loss: 0.9403 - val_accuracy: 0.8274 - val_loss: 0.7518 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 891ms/step - accuracy: 0.7284 - loss: 0.8717 - val_accuracy: 0.8481 - val_loss: 0.7260 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 815ms/step - accuracy: 0.7343 - loss: 0.8561 - val_accuracy: 0.8625 - val_loss: 0.6908 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 801ms/step - accuracy: 0.7545 - loss: 0.8173 - val_accuracy: 0.8721 - val_loss: 0.6663 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 410ms/step - accuracy: 0.7670 - loss: 0.8056 - val_accuracy: 0.8886 - val_loss: 0.6548 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 246ms/step - accuracy: 0.7877 - loss: 0.7735 - val_accuracy: 0.8728 - val_loss: 0.6408 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 249ms/step - accuracy: 0.7973 - loss: 0.7518 - val_accuracy: 0.9063 - val_loss: 0.6197 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 245ms/step - accuracy: 0.8086 - loss: 0.7456 - val_accuracy: 0.8901 - val_loss: 0.6418 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 244ms/step - accuracy: 0.8145 - loss: 0.7382 - val_accuracy: 0.9027 - val_loss: 0.6128 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m698s\u001b[0m 2s/step - accuracy: 0.8220 - loss: 0.7265 - val_accuracy: 0.9111 - val_loss: 0.6080 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 286ms/step - accuracy: 0.8226 - loss: 0.7265 - val_accuracy: 0.9089 - val_loss: 0.5906 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 272ms/step - accuracy: 0.8293 - loss: 0.7164 - val_accuracy: 0.9038 - val_loss: 0.6088 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.8393 - loss: 0.6990 - val_accuracy: 0.9156 - val_loss: 0.5761 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 260ms/step - accuracy: 0.8497 - loss: 0.6766 - val_accuracy: 0.9222 - val_loss: 0.5739 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 247ms/step - accuracy: 0.8496 - loss: 0.6793 - val_accuracy: 0.9012 - val_loss: 0.6012 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 236ms/step - accuracy: 0.8512 - loss: 0.6831 - val_accuracy: 0.9159 - val_loss: 0.5692 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 247ms/step - accuracy: 0.8538 - loss: 0.6776 - val_accuracy: 0.9395 - val_loss: 0.5425 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 253ms/step - accuracy: 0.8563 - loss: 0.6630 - val_accuracy: 0.9325 - val_loss: 0.5502 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 264ms/step - accuracy: 0.8647 - loss: 0.6637 - val_accuracy: 0.9406 - val_loss: 0.5432 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.8593 - loss: 0.6620\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 266ms/step - accuracy: 0.8593 - loss: 0.6620 - val_accuracy: 0.9263 - val_loss: 0.5596 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 266ms/step - accuracy: 0.8813 - loss: 0.6259 - val_accuracy: 0.9428 - val_loss: 0.5296 - learning_rate: 5.0000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 248ms/step - accuracy: 0.8917 - loss: 0.6095 - val_accuracy: 0.9421 - val_loss: 0.5239 - learning_rate: 5.0000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 261ms/step - accuracy: 0.8943 - loss: 0.6090 - val_accuracy: 0.9381 - val_loss: 0.5307 - learning_rate: 5.0000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 272ms/step - accuracy: 0.8987 - loss: 0.6017 - val_accuracy: 0.9421 - val_loss: 0.5163 - learning_rate: 5.0000e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 247ms/step - accuracy: 0.9014 - loss: 0.5971 - val_accuracy: 0.9251 - val_loss: 0.5517 - learning_rate: 5.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      " Fold 5 Accuracy: 0.9421\n",
      "\n",
      " Average Validation Accuracy over 5 folds: 0.9308\n"
     ]
    }
   ],
   "source": [
    "run_kfold_training(X_all, X_feat_all, X_eye_segment, y_cat, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88098727-ed57-4500-9963-7d67692b8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02325fae-4056-4ac3-9bf8-41a8d1f08513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def run_kfold_training(X_eeg, X_feat, X_eye, y_cat, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(y_cat)))):\n",
    "        print(f\"\\n Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        train_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, train_idx)\n",
    "        val_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, val_idx, shuffle=False)\n",
    "\n",
    "        model = build_triple_branch_model()\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "        lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "        model.fit(train_gen, validation_data=val_gen, epochs=30, callbacks=[es, lr], verbose=1)\n",
    "\n",
    "        val_acc = model.evaluate(val_gen, verbose=0)[1]\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\" Fold {fold + 1} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # ✅ Compute confusion matrix and save\n",
    "        y_true, y_pred = [], []\n",
    "        for batch in val_gen:\n",
    "            inputs, labels = batch\n",
    "            preds = model.predict(inputs, verbose=0)\n",
    "            y_true.extend(np.argmax(labels, axis=1))\n",
    "            y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Neutral\", \"Sad\", \"Fear\", \"Happy\"])\n",
    "        disp.plot(cmap='Blues', values_format='d')\n",
    "        os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
    "        plt.title(f\"Confusion Matrix - Fold {fold + 1}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"confusion_matrices/conf_matrix_fold_{fold+1}.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Optional: Print precision/recall/F1\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=[\"Neutral\", \"Sad\", \"Fear\", \"Happy\"]))\n",
    "\n",
    "    print(f\"\\n ✅ Average Validation Accuracy over {n_splits} folds: {np.mean(val_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dce9304-c7c3-4c7a-b0c4-81be29765638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00dfc56c-5c62-49fb-9f7d-650f3c5fc392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True)  # Create results dir\n",
    "\n",
    "class EEGTripleInputGenerator(Sequence):\n",
    "    def __init__(self, X1, X2, X3, y, indices, batch_size=32, shuffle=True):\n",
    "        self.X1, self.X2, self.X3, self.y = X1, X2, X3, y\n",
    "        self.indices = np.array(indices)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        batch_idx = self.indices[i*self.batch_size:(i+1)*self.batch_size]\n",
    "        return {\n",
    "            \"eeg_input\": self.X1[batch_idx],\n",
    "            \"eeg_feat_input\": self.X2[batch_idx],\n",
    "            \"eye_input\": self.X3[batch_idx],\n",
    "        }, self.y[batch_idx]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "def plot_training_curves(history, fold):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"Training and Validation Accuracy (Fold {fold})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/train_curves_fold{fold}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, fold, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Confusion Matrix - Fold {fold}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/conf_matrix_fold{fold}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def run_kfold_training(X_eeg, X_feat, X_eye, y_cat, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "    labels = [\"Neutral\", \"Sad\", \"Fear\", \"Happy\"]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(np.arange(len(y_cat)))):\n",
    "        print(f\"\\n📂 Fold {fold + 1}/{n_splits}\")\n",
    "        train_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, train_idx)\n",
    "        val_gen = EEGTripleInputGenerator(X_eeg, X_feat, X_eye, y_cat, val_idx, shuffle=False)\n",
    "\n",
    "        model = build_triple_branch_model()\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "        lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "        history = model.fit(train_gen,\n",
    "                            validation_data=val_gen,\n",
    "                            epochs=30,\n",
    "                            callbacks=[es, lr],\n",
    "                            verbose=1)\n",
    "\n",
    "        # Save training curve\n",
    "        plot_training_curves(history, fold + 1)\n",
    "\n",
    "        # Evaluate\n",
    "        val_acc = model.evaluate(val_gen, verbose=0)[1]\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f\"✅ Fold {fold + 1} Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Save model\n",
    "        model.save(f\"results/model_fold{fold+1}.keras\")\n",
    "\n",
    "        # Predict labels\n",
    "        y_true = np.argmax(y_cat[val_idx], axis=1)\n",
    "        y_pred = []\n",
    "\n",
    "        for batch_x, _ in val_gen:\n",
    "            preds = model.predict(batch_x, verbose=0)\n",
    "            y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "        y_pred = np.array(y_pred)\n",
    "\n",
    "        # Save classification report\n",
    "        report = classification_report(y_true, y_pred, target_names=labels, digits=4)\n",
    "        with open(f\"results/classification_report_fold{fold+1}.txt\", \"w\") as f:\n",
    "            f.write(report)\n",
    "\n",
    "        print(report)\n",
    "\n",
    "        # Save confusion matrix\n",
    "        plot_confusion(y_true, y_pred, fold + 1, labels)\n",
    "\n",
    "    print(f\"\\n🏁 Average Validation Accuracy over {n_splits} folds: {np.mean(val_accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dbc458b-8049-4558-af44-7a467c4856f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Fold 1/5\n",
      "Epoch 1/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 249ms/step - accuracy: 0.3319 - loss: 7.1817 - val_accuracy: 0.4882 - val_loss: 1.9791 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 238ms/step - accuracy: 0.4277 - loss: 2.2072 - val_accuracy: 0.5516 - val_loss: 1.2409 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 257ms/step - accuracy: 0.4743 - loss: 1.4234 - val_accuracy: 0.5623 - val_loss: 1.1492 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 249ms/step - accuracy: 0.5224 - loss: 1.2817 - val_accuracy: 0.6206 - val_loss: 1.0493 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 245ms/step - accuracy: 0.5654 - loss: 1.1425 - val_accuracy: 0.6656 - val_loss: 0.9720 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 254ms/step - accuracy: 0.6195 - loss: 1.0557 - val_accuracy: 0.7117 - val_loss: 0.9248 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 246ms/step - accuracy: 0.6614 - loss: 0.9872 - val_accuracy: 0.7895 - val_loss: 0.8203 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 256ms/step - accuracy: 0.6962 - loss: 0.9239 - val_accuracy: 0.7928 - val_loss: 1.5172 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 249ms/step - accuracy: 0.7115 - loss: 1.2886 - val_accuracy: 0.8429 - val_loss: 0.7208 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 816ms/step - accuracy: 0.7518 - loss: 0.8595 - val_accuracy: 0.8673 - val_loss: 0.6868 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 947ms/step - accuracy: 0.7777 - loss: 0.8044 - val_accuracy: 0.8875 - val_loss: 0.6589 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 814ms/step - accuracy: 0.7920 - loss: 0.7751 - val_accuracy: 0.9034 - val_loss: 0.6250 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 836ms/step - accuracy: 0.8208 - loss: 0.7321 - val_accuracy: 0.9126 - val_loss: 0.5988 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 773ms/step - accuracy: 0.8218 - loss: 0.7244 - val_accuracy: 0.9270 - val_loss: 0.5748 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 750ms/step - accuracy: 0.8280 - loss: 0.7123 - val_accuracy: 0.9115 - val_loss: 0.5850 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 854ms/step - accuracy: 0.8483 - loss: 0.6860 - val_accuracy: 0.9406 - val_loss: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 836ms/step - accuracy: 0.8558 - loss: 0.6759 - val_accuracy: 0.9229 - val_loss: 0.5666 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 745ms/step - accuracy: 0.8581 - loss: 0.6751 - val_accuracy: 0.9414 - val_loss: 0.5372 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 754ms/step - accuracy: 0.8762 - loss: 0.6569 - val_accuracy: 0.9451 - val_loss: 0.5196 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 761ms/step - accuracy: 0.8716 - loss: 0.6455 - val_accuracy: 0.9473 - val_loss: 0.5256 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 763ms/step - accuracy: 0.8833 - loss: 0.6267 - val_accuracy: 0.9495 - val_loss: 0.5133 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 805ms/step - accuracy: 0.8753 - loss: 0.6312 - val_accuracy: 0.9532 - val_loss: 0.4977 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 405ms/step - accuracy: 0.8848 - loss: 0.6227 - val_accuracy: 0.9543 - val_loss: 0.5027 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 252ms/step - accuracy: 0.8907 - loss: 0.6164 - val_accuracy: 0.9580 - val_loss: 0.4913 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 257ms/step - accuracy: 0.8902 - loss: 0.6102 - val_accuracy: 0.9594 - val_loss: 0.4917 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 242ms/step - accuracy: 0.8950 - loss: 0.5992 - val_accuracy: 0.9377 - val_loss: 0.5149 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 254ms/step - accuracy: 0.9013 - loss: 0.5922 - val_accuracy: 0.9528 - val_loss: 0.4891 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 246ms/step - accuracy: 0.8999 - loss: 0.5987 - val_accuracy: 0.9583 - val_loss: 0.4832 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 264ms/step - accuracy: 0.8888 - loss: 0.6079 - val_accuracy: 0.9576 - val_loss: 0.4757 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m339/339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 252ms/step - accuracy: 0.9066 - loss: 0.5877 - val_accuracy: 0.9598 - val_loss: 0.4780 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "✅ Fold 1 Accuracy: 0.9576\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'batch_outputs' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_kfold_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_feat_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_eye_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_cat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 98\u001b[0m, in \u001b[0;36mrun_kfold_training\u001b[1;34m(X_eeg, X_feat, X_eye, y_cat, n_splits)\u001b[0m\n\u001b[0;32m     95\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_x, _ \u001b[38;5;129;01min\u001b[39;00m val_gen:\n\u001b[1;32m---> 98\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     y_pred\u001b[38;5;241m.\u001b[39mextend(np\u001b[38;5;241m.\u001b[39margmax(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:573\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    571\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_end()\n\u001b[0;32m    572\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure_up_to(\n\u001b[1;32m--> 573\u001b[0m     \u001b[43mbatch_outputs\u001b[49m, potentially_ragged_concat, outputs\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mmap_structure(convert_to_np_if_not_ragged, outputs)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'batch_outputs' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "run_kfold_training(X_all, X_feat_all, X_eye_segment, y_cat, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd9e4a-588f-4418-862f-cc793af7e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
